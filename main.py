import cv2
import random
from collections import deque
import mediapipe as mp  # [MP] biblioteka do analizy d≈Çoni

# [MP] Inicjalizacja MediaPipe Hands
mp_hands = mp.solutions.hands #pobiera modu≈Ç hands z pakietu mediapipe do ykrywania i ≈õledzenia d≈Çoni
mp_drawing = mp.solutions.drawing_utils #pobiera modu≈Ç drawing_utils z mediapipe do rysowania landmark√≥w i po≈ÇƒÖcze≈Ñ d≈Çoni na obrazie (linie i punkty)


# Funkcja "za≈õlepka" ‚Äì klasyfikacja statyczna
#with to konstrukcja w Pythonie u≈ºywana do zarzƒÖdzania kontekstem.
# Oznacza to, ≈ºe automatycznie wykonuje pewne czynno≈õci przy wej≈õciu i wyj≈õciu z bloku kodu.
def klasyfikuj_stat(frame):
    # [MP] Utw√≥rz obiekt Hands dla pojedynczej klatki (statyczny gest)
    with mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.3) as hands:
        # [MP] Konwersja obrazu na RGB dla mediapipe zamiast BGR
        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = hands.process(image_rgb)

        # [MP] Je≈õli wykryto d≈Ço≈Ñ ‚Äì narysuj szkielet
        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

    # Losowy wyb√≥r litery statycznej albo brak ('-')
    litery_stat = ['A', 'B', 'C', 'D', 'E', '-', 'F', 'G', 'H']
    return random.choice(litery_stat)

# Funkcja "za≈õlepka" ‚Äì klasyfikacja dynamiczna
def klasyfikuj_dyn(buffer):
    # Utw√≥rz obiekt Hands do przetwarzania sekwencji klatek (ruch d≈Çoni)
    with mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.3) as hands:
        for frame in buffer:
            # Konwersja ka≈ºdej klatki na RGB
            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = hands.process(image_rgb)

            # Je≈õli wykryto d≈Ço≈Ñ ‚Äì narysuj szkielet
            if results.multi_hand_landmarks:
                for hand_landmarks in results.multi_hand_landmarks:
                    mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

    # Losowy wyb√≥r litery dynamicznej albo brak ('-')
    litery_dyn = ['ƒÑ', 'ƒò', '≈Å', '√ì', '-', '≈ö', '≈π', '≈ª']
    return random.choice(litery_dyn)

def przetworz_video(video_path):
    #Przetwarza pojedynczy plik wideo
    print(f"\n‚ñ∂Ô∏è Rozpoczynam analizƒô pliku: {video_path}") #doda≈Çam emoji!
    bufor = deque(maxlen=25) #bufor stworzony
    cap = cv2.VideoCapture(video_path) #odczytujemy ttym razem z pliku a nie z kamery

    if not cap.isOpened():
        print(f"‚ùå Nie mo≈ºna otworzyƒá pliku wideo: {video_path}")
        return

    while True:
        ret, frame = cap.read() #odczytywanie tylko jednej klatki!
        if not ret:
            print(f"üé¨ Koniec filmu: {video_path}")
            break

        # Dodaj klatkƒô do bufora
        bufor.append(frame)

        # Je≈õli bufor jest jeszcze niepe≈Çny, kontynuuj
        if len(bufor) < bufor.maxlen:
            cv2.imshow("PodglƒÖd", frame) #dziƒôki temu widzimy nasz filmik obok wy≈õwietlony
            if cv2.waitKey(30) & 0xFF == ord('q'): #da≈Çam trovchƒô wiƒôcej czasu na przeczekanie, by≈Ço 1ms ale teraz my≈õlƒô ≈ºe lepiej jak wstrzyma troszke d≈Çu≈ºej
                break
            continue

        # Klasyfikacja statyczna
        wynik_stat = klasyfikuj_stat(bufor[0])

        if wynik_stat == '-':
            cv2.imshow("PodglƒÖd", frame)
            if cv2.waitKey(30) & 0xFF == ord('q'):
                break
            continue

        # Sprawd≈∫, czy znak statyczny mo≈ºe byƒá poczƒÖtkiem dynamicznego
        potencjalnie_dynamiczne = {'A', 'B', 'C'} # przyk≈Çadowy zbi√≥r
        if wynik_stat in potencjalnie_dynamiczne:
            wynik_dyn = klasyfikuj_dyn(list(bufor))
            if wynik_dyn != '-':
                print(f"üí´ Wykryto gest dynamiczny: {wynik_dyn}")
                bufor.clear() # wyczy≈õƒá bufor po dynamicznym
            else:
                print(f"üëå Wykryto gest statyczny: {wynik_stat}")
        else:
            print(f"üëå Wykryto gest statyczny: {wynik_stat}")

        # Wy≈õwietl podglƒÖd z kamery
        cv2.imshow("PodglƒÖd", frame)
        if cv2.waitKey(30) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

def main():
    # üîπ Lista plik√≥w wideo do przetworzenia
    videos = [
        "pfa1.avi",
        "pfa2.mp4",
        "pfa3.avi",
        "pfa4.avi"
    ]

    for video in videos:
        przetworz_video(video)

    print("\n‚úÖ Wszystkie pliki zosta≈Çy przetworzone!")

if __name__ == "__main__": #uruchomi≈Ç main() tylko wtedy, gdy ten plik zosta≈Ç uruchomiony bezpo≈õrednio, a nie np. zaimportowany z innego pliku.
    main()