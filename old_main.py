import os #operacje na plikach, folderach, ≈õcie≈ºkach itp
import math
import random
import cv2 #biblioteka OpenCV do obs≈Çugi obrazu i wideo
from collections import deque #dwustronna kolejka (bufor klatek)
import mediapipe as mp
print("MediaPipe dzia≈Ça poprawnie!")

# ============================================================
#  KONFIGURACJA
# ============================================================

# Wy≈ÇƒÖczenie log√≥w TensorFlow i MediaPipe
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"
os.environ["GLOG_minloglevel"] = "3"

# Inicjalizacja MediaPipe
mp_hands = mp.solutions.hands #model do wykrywania d≈Çoni
mp_drawing = mp.solutions.drawing_utils #narzƒôdzia do rysowania szkieletu d≈Çoni na obrazie


# ============================================================
#  FUNKCJE POMOCNICZE
# ============================================================

def ekstraktuj_punkty(hand_landmarks):
    """Zwraca znormalizowane punkty d≈Çoni (x, y) wzglƒôdem nadgarstka."""
    punkty = [(lm.x, lm.y) for lm in hand_landmarks.landmark] #Pobiera wsp√≥≈Çrzƒôdne wszystkich punkt√≥w d≈Çoni
    ref_x, ref_y = punkty[0]
    punkty_shifted = [(x - ref_x, y - ref_y) for x, y in punkty] #Przesuwa uk≈Çad odniesienia tak, ≈ºeby punkt 0 (nadgarstek) by≈Ç w (0, 0)

    base_len = math.dist(punkty[0], punkty[9]) or 1.0 #Normalizuje rozmiar d≈Çoni ‚Äî dzieli przez odleg≈Ço≈õƒá miƒôdzy punktem 0 (nadgarstek) a 9 (≈õrodek d≈Çoni).
    return [(x / base_len, y / base_len) for x, y in punkty_shifted] #Zwraca listƒô punkt√≥w (x, y) znormalizowanych ‚Äî czyli niezale≈ºnych od odleg≈Ço≈õci i po≈Ço≈ºenia.


def porownaj_szkielety(szk1, szk2):
    """Por√≥wnuje dwa szkielety d≈Çoni ‚Äî im mniejszy dystans, tym wiƒôksze podobie≈Ñstwo."""
    if len(szk1) != len(szk2):
        return float("inf")
    return sum(math.dist(a, b) for a, b in zip(szk1, szk2)) / len(szk1)
#Liczy ≈õredniƒÖ odleg≈Ço≈õƒá miƒôdzy odpowiadajƒÖcymi sobie punktami, im mniejsza warto≈õƒá tym bardziej podobne gesty

# ============================================================
#  WCZYTYWANIE WZORC√ìW STATYCZNYCH
# ============================================================

def wczytaj_wzorce(folder_path):
    """Wczytuje obrazy wzorc√≥w gest√≥w statycznych z folderu."""
    print(f"üìÇ Wczytywanie wzorc√≥w z: {folder_path}")
    wzorce = {}

    with mp_hands.Hands(static_image_mode=True, max_num_hands=1) as hands: #Je≈õli znajdzie d≈Ço≈Ñ
        for filename in os.listdir(folder_path):
            path = os.path.join(folder_path, filename)
            frame = cv2.imread(path)
            if frame is None:
                print(f"‚ö†Ô∏è Nie mo≈ºna wczytaƒá pliku: {filename}")
                continue

            results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
            if not results.multi_hand_landmarks:
                print(f"‚ö†Ô∏è Brak d≈Çoni w {filename}")
                continue

            label = os.path.splitext(filename)[0].lower() #etykieta gestu to nazwa pliku bez rozszerzenia
            wzorce[label] = ekstraktuj_punkty(results.multi_hand_landmarks[0])  #zapisuje jej znormalizowany szkielet
            print(f"‚úÖ Za≈Çadowano: {label}")

    print(f"üìÅ ≈ÅƒÖcznie {len(wzorce)} wzorc√≥w wczytanych.\n")
    return wzorce


# ============================================================
#  PRZETWARZANIE WIDEO
# ============================================================

def przetworz_video(video_path, wzorce_stat):
    """Analizuje pojedynczy plik wideo i rozpoznaje gesty d≈Çoni."""
    print(f"\n‚ñ∂Ô∏è Analiza pliku: {video_path}")

    if not os.path.exists(video_path):
        print(f"‚ùå Nie znaleziono pliku: {video_path}")
        return

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"‚ùå Nie mo≈ºna otworzyƒá: {video_path}")
        return

    # Bufor klatek i stabilizacja
    bufor = deque(maxlen=25)
    stable_stat = {"last": None, "count": 0}
    stable_dyn = {"last": None, "count": 0}

    # Jeden obiekt Hands dla ca≈Çego wideo
    with mp_hands.Hands(
        static_image_mode=False,
        max_num_hands=1,
        min_detection_confidence=0.6,
        min_tracking_confidence=0.9
    ) as hands:

        while True:
            ret, frame = cap.read()
            if not ret:
                print(f"üé¨ Koniec filmu: {video_path}")
                break

            bufor.append(frame)
            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = hands.process(image_rgb)

            if results.multi_hand_landmarks:
                hand_landmarks = results.multi_hand_landmarks[0]
                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS) #Rysuje punkty i po≈ÇƒÖczenia na obrazie

                # --- Klasyfikacja statyczna ---
                szkiel_test = ekstraktuj_punkty(hand_landmarks) #Oblicza aktualny szkielet
                najlepszy, min_dist = "-", float("inf")

                for litera, szkiel_wzorzec in wzorce_stat.items():
                    dist = porownaj_szkielety(szkiel_test, szkiel_wzorzec) #Por√≥wnuje go z ka≈ºdym wzorcem
                    if dist < min_dist:
                        najlepszy, min_dist = litera, dist

                # --- Stabilizacja wyniku ---
                if najlepszy == stable_stat["last"]:
                    stable_stat["count"] += 1
                else:
                    stable_stat["count"] = 0
                stable_stat["last"] = najlepszy

                #wymaga ≈ºeby ten sam gest pojawi≈Ç siƒô kilka razy z rzƒôdu
                if stable_stat["count"] >= 15:
                    print(f"‚úã Statyczny gest: {najlepszy}")
                    stable_stat["count"] = 0

                # --- Klasyfikacja dynamiczna (za≈õlepka) ---
                if len(bufor) > 1:
                    dyn_gest = random.choice(["ƒÑ", "ƒò", "≈Å", "√ì", "-", "≈ö", "≈π", "≈ª"])
                    if dyn_gest == stable_dyn["last"]:
                        stable_dyn["count"] += 1
                    else:
                        stable_dyn["count"] = 0
                    stable_dyn["last"] = dyn_gest

                    if stable_dyn["count"] >= 5:
                        print(f"üéØ Dynamiczny gest: {dyn_gest}")
                        stable_dyn["count"] = 0

            # PodglƒÖd wideo
            cv2.imshow("PodglƒÖd", frame)
            if cv2.waitKey(30) & 0xFF == ord("q"):
                break

    cap.release()
    cv2.destroyAllWindows()


# ============================================================
#  MAIN
# ============================================================

def main():
    videos = ["pfa2.mp4"]
    wzorce_stat = wczytaj_wzorce(r"C:\Users\Ola Sawicka\Desktop\semestr 7\thesis\statycze")

    for video in videos:
        przetworz_video(video, wzorce_stat)

    print("\n‚úÖ Wszystkie pliki zosta≈Çy przetworzone!")


if __name__ == "__main__":
    main()
